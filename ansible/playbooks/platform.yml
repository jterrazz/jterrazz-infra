---
# Platform Services Playbook
# Installs platform services via Helm and kubectl on the production VPS.
# All kubectl/helm commands run ON the VPS (no external k8s API access needed).

- name: Platform Services Deployment
  hosts: all
  become: true
  gather_facts: true

  vars:
    kubeconfig_remote: /etc/rancher/k3s/k3s.yaml
    manifest_dest: /tmp/k8s-manifests
    templates_dir: "{{ playbook_dir }}/../templates"
    platform_chart: "{{ manifest_dest }}/kubernetes/charts/platform"
    portainer_admin_password: "{{ portainer_password | default('changeme-on-first-login') }}"

  tasks:
    # ========================================
    # Pre-flight validation
    # ========================================

    - name: Validate required secrets
      ansible.builtin.assert:
        that:
          - cloudflare_api_token is defined and cloudflare_api_token | length > 0
          - infisical_client_id is defined and infisical_client_id | length > 0
          - infisical_client_secret is defined and infisical_client_secret | length > 0
          - registry_password is defined and registry_password | length > 0
        fail_msg: >
          Missing required secrets. Ensure cloudflare_api_token, infisical_client_id,
          infisical_client_secret, and registry_password are passed as extra vars.

    # ========================================
    # Base infrastructure
    # ========================================

    - name: Wait for Traefik to be ready
      ansible.builtin.shell:
        cmd: |
          set -o pipefail
          kubectl wait --for=condition=complete job -l helmcharts.helm.cattle.io/chart=traefik -n kube-system --timeout=1s
        executable: /bin/bash
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: traefik_wait
      retries: 60
      delay: 2
      until: traefik_wait.rc == 0
      changed_when: false

    - name: Create manifest directory on VPS
      ansible.builtin.file:
        path: "{{ manifest_dest }}"
        state: directory
        mode: "0755"

    - name: Copy infrastructure manifests to VPS
      ansible.builtin.copy:
        src: "{{ playbook_dir }}/../../kubernetes/"
        dest: "{{ manifest_dest }}/kubernetes/"
        mode: "0644"

    # ========================================
    # Tailscale IP
    # ========================================

    - name: Get Tailscale IP
      ansible.builtin.command: tailscale ip -4
      register: platform_tailscale_ip_result
      changed_when: false

    - name: Set Tailscale IP fact
      ansible.builtin.set_fact:
        tailscale_ip: "{{ platform_tailscale_ip_result.stdout | trim }}"

    # ========================================
    # Registry setup
    # ========================================

    - name: Install apache2-utils for htpasswd
      ansible.builtin.apt:
        name: apache2-utils
        state: present
        update_cache: true

    - name: Generate htpasswd hash for registry
      ansible.builtin.shell:
        cmd: |
          set -o pipefail
          htpasswd -nbB deploy "{{ registry_password }}"
        executable: /bin/bash
      register: htpasswd_result
      changed_when: false
      no_log: true

    - name: Set registry facts
      ansible.builtin.set_fact:
        registry_htpasswd: "{{ htpasswd_result.stdout | trim }}"
        server_ip: "{{ hostvars[inventory_hostname]['ansible_host'] | default(ansible_default_ipv4.address) }}"
      no_log: true

    - name: Template registry manifest with secrets
      ansible.builtin.template:
        src: "{{ templates_dir }}/kubernetes/registry.yaml.j2"
        dest: "{{ manifest_dest }}/kubernetes/platform/registry.yaml"
        mode: "0644"

    - name: Template registry pull secret for app namespaces
      ansible.builtin.template:
        src: "{{ templates_dir }}/kubernetes/registry-pull-secret.yaml.j2"
        dest: "{{ manifest_dest }}/registry-pull-secret.yaml"
        mode: "0644"

    - name: Apply registry pull secret
      ansible.builtin.command: kubectl apply -f {{ manifest_dest }}/registry-pull-secret.yaml
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: pull_secret_result
      changed_when: "'created' in pull_secret_result.stdout or 'configured' in pull_secret_result.stdout"

    # Make released PVs available for rebinding (for data persistence across redeployments)
    - name: Clear claimRef from released PVs
      ansible.builtin.shell:
        cmd: |
          set -o pipefail
          for pv in $(kubectl get pv -o jsonpath='{.items[?(@.status.phase=="Released")].metadata.name}'); do
            kubectl patch pv $pv -p '{"spec":{"claimRef":null}}' --type=merge
          done
        executable: /bin/bash
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: pv_clear
      changed_when: pv_clear.stdout != ''
      failed_when: false

    - name: Deploy base infrastructure manifests
      ansible.builtin.command:
        cmd: kubectl apply -k {{ manifest_dest }}/kubernetes/infrastructure/environments/production
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: infra_result
      changed_when: "'created' in infra_result.stdout or 'configured' in infra_result.stdout"

    # ========================================
    # Helm setup
    # ========================================

    - name: Check if Helm is installed
      ansible.builtin.command: which helm
      register: helm_check
      changed_when: false
      failed_when: false

    - name: Install Helm
      when: helm_check.rc != 0
      block:
        - name: Download Helm install script
          ansible.builtin.get_url:
            url: https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
            dest: /tmp/get_helm.sh
            mode: "0755"

        - name: Run Helm install script
          ansible.builtin.command: /tmp/get_helm.sh
          environment:
            DESIRED_VERSION: v3.20.0
          changed_when: true

        - name: Cleanup Helm install script
          ansible.builtin.file:
            path: /tmp/get_helm.sh
            state: absent

    - name: Add Helm repositories
      ansible.builtin.command: "helm repo add {{ item.name }} {{ item.url }}"
      loop:
        - { name: jetstack, url: "https://charts.jetstack.io" }
        - { name: external-dns, url: "https://kubernetes-sigs.github.io/external-dns" }
        - { name: signoz, url: "https://charts.signoz.io" }
        - { name: community-charts, url: "https://community-charts.github.io/helm-charts" }
        - name: infisical
          url: "https://dl.cloudsmith.io/public/infisical/helm-charts/helm/charts/"
        - { name: portainer, url: "https://portainer.github.io/k8s/" }
      register: repo_add
      changed_when: "'has been added' in repo_add.stdout"
      failed_when: repo_add.rc != 0 and 'already exists' not in repo_add.stderr

    - name: Update Helm repositories
      ansible.builtin.command: helm repo update
      changed_when: false

    # ========================================
    # Secrets
    # ========================================

    - name: Create Cloudflare API token secret for networking
      ansible.builtin.shell:
        cmd: |
          set -o pipefail
          kubectl create secret generic cloudflare-api-token \
            --from-literal=api-token="{{ cloudflare_api_token }}" \
            --namespace platform-networking \
            --dry-run=client -o yaml | kubectl apply -f -
        executable: /bin/bash
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: net_secret
      changed_when: "'created' in net_secret.stdout or 'configured' in net_secret.stdout"
      no_log: true

    - name: Create Infisical credentials secret
      ansible.builtin.shell:
        cmd: |
          set -o pipefail
          kubectl create secret generic infisical-credentials \
            --from-literal=clientId="{{ infisical_client_id }}" \
            --from-literal=clientSecret="{{ infisical_client_secret }}" \
            --namespace platform-secrets \
            --dry-run=client -o yaml | kubectl apply -f -
        executable: /bin/bash
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: infisical_secret
      changed_when: "'created' in infisical_secret.stdout or 'configured' in infisical_secret.stdout"
      no_log: true

    - name: Create n8n encryption key secret
      ansible.builtin.shell:
        cmd: |
          set -o pipefail
          kubectl create secret generic n8n-encryption-key \
            --from-literal=N8N_ENCRYPTION_KEY="{{ n8n_encryption_key }}" \
            --namespace platform-automation \
            --dry-run=client -o yaml | kubectl apply -f -
        executable: /bin/bash
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      when: n8n_encryption_key is defined and n8n_encryption_key | length > 0
      register: n8n_secret
      changed_when: "'created' in n8n_secret.stdout or 'configured' in n8n_secret.stdout"
      no_log: true

    - name: Create OpenClaw secrets
      ansible.builtin.shell:
        cmd: |
          set -o pipefail
          kubectl create secret generic openclaw-secrets \
            --from-literal=GATEWAY_TOKEN="{{ openclaw_gateway_token }}" \
            --from-literal=CLAUDE_TOKEN="{{ openclaw_claude_token }}" \
            --namespace platform-automation \
            --dry-run=client -o yaml | kubectl apply -f -
        executable: /bin/bash
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      when: openclaw_gateway_token is defined and openclaw_gateway_token | length > 0
      register: openclaw_secret
      changed_when: "'created' in openclaw_secret.stdout or 'configured' in openclaw_secret.stdout"
      no_log: true

    # ========================================
    # Adopt existing resources into platform chart Helm releases
    # One-time migration: resources created by kubectl apply need Helm labels
    # to be adopted by helm upgrade --install. Safe to run repeatedly.
    # ========================================

    - name: Adopt existing resources into platform chart releases
      ansible.builtin.shell:
        cmd: |
          set -o pipefail
          adopt_resource() {
            local kind=$1 name=$2 namespace=$3 release=$4
            if kubectl get "$kind" "$name" -n "$namespace" 2>/dev/null | grep -q "$name"; then
              kubectl annotate "$kind" "$name" -n "$namespace" \
                meta.helm.sh/release-name="$release" \
                meta.helm.sh/release-namespace="$namespace" \
                --overwrite 2>/dev/null || true
              kubectl label "$kind" "$name" -n "$namespace" \
                app.kubernetes.io/managed-by=Helm \
                --overwrite 2>/dev/null || true
            fi
          }
          # SigNoz
          adopt_resource certificate.cert-manager.io signoz-tls platform-observability signoz-platform
          adopt_resource ingressroute.traefik.io signoz platform-observability signoz-platform
          # n8n
          adopt_resource certificate.cert-manager.io n8n-tls platform-automation n8n-platform
          adopt_resource ingressroute.traefik.io n8n platform-automation n8n-platform
          adopt_resource persistentvolumeclaim n8n-data platform-automation n8n-platform
          # OpenClaw
          adopt_resource certificate.cert-manager.io openclaw-tls platform-automation openclaw-platform
          adopt_resource ingressroute.traefik.io openclaw platform-automation openclaw-platform
          adopt_resource persistentvolumeclaim openclaw-data platform-automation openclaw-platform
          # Portainer
          adopt_resource certificate.cert-manager.io portainer-tls platform-management portainer-platform
          adopt_resource ingressroute.traefik.io portainer platform-management portainer-platform
          adopt_resource persistentvolumeclaim portainer-data platform-management portainer-platform
          echo "done"
        executable: /bin/bash
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      changed_when: false
      failed_when: false

    - name: Adopt cluster-scoped PVs into platform chart releases
      ansible.builtin.shell:
        cmd: |
          set -o pipefail
          adopt_pv() {
            local name=$1 release=$2 namespace=$3
            if kubectl get pv "$name" 2>/dev/null | grep -q "$name"; then
              kubectl annotate pv "$name" \
                meta.helm.sh/release-name="$release" \
                meta.helm.sh/release-namespace="$namespace" \
                --overwrite 2>/dev/null || true
              kubectl label pv "$name" \
                app.kubernetes.io/managed-by=Helm \
                --overwrite 2>/dev/null || true
            fi
          }
          adopt_pv n8n-data n8n-platform platform-automation
          adopt_pv openclaw-data openclaw-platform platform-automation
          adopt_pv portainer-data portainer-platform platform-management
          echo "done"
        executable: /bin/bash
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      changed_when: false
      failed_when: false

    # ========================================
    # Platform services â€” Helm installs
    # Order matters: cert-manager first (TLS), then networking, then apps.
    # Each service uses helm.yaml for its upstream chart config and
    # platform.yaml for ingress/cert/storage via the shared platform chart.
    # ========================================

    # 1. cert-manager
    - name: Install cert-manager via Helm
      ansible.builtin.command: >
        helm upgrade --install cert-manager jetstack/cert-manager
        --namespace platform-networking
        --version v1.19.3
        --values {{ manifest_dest }}/kubernetes/platform/cert-manager/helm.yaml
        --wait
        --timeout 5m
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: certmanager_result
      changed_when: "'has been upgraded' in certmanager_result.stdout or 'has been installed' in certmanager_result.stdout"

    - name: Wait for cert-manager webhook to be ready
      ansible.builtin.command:
        cmd: kubectl rollout status deployment/cert-manager-webhook -n platform-networking --timeout=120s
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      changed_when: false

    - name: Apply cert-manager ClusterIssuers
      ansible.builtin.command: kubectl apply -f {{ manifest_dest }}/kubernetes/platform/cert-manager/issuers.yaml
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: issuers_result
      changed_when: "'created' in issuers_result.stdout or 'configured' in issuers_result.stdout"

    # 2. external-dns
    - name: Install external-dns via Helm
      ansible.builtin.command: >
        helm upgrade --install external-dns external-dns/external-dns
        --namespace platform-networking
        --version 1.20.0
        --values {{ manifest_dest }}/kubernetes/platform/external-dns/helm.yaml
        --wait
        --timeout 5m
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: externaldns_result
      changed_when: "'has been upgraded' in externaldns_result.stdout or 'has been installed' in externaldns_result.stdout"

    # 3. Infisical secrets operator
    - name: Install Infisical secrets operator via Helm
      ansible.builtin.command: >
        helm upgrade --install infisical infisical/secrets-operator
        --namespace platform-secrets
        --version 0.10.25
        --values {{ manifest_dest }}/kubernetes/platform/infisical/helm.yaml
        --wait
        --timeout 5m
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: infisical_helm_result
      changed_when: "'has been upgraded' in infisical_helm_result.stdout or 'has been installed' in infisical_helm_result.stdout"

    # 4. SigNoz observability platform
    - name: Apply SigNoz storage manifests
      ansible.builtin.command: kubectl apply -f {{ manifest_dest }}/kubernetes/platform/signoz/storage.yaml
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: signoz_storage_result
      changed_when: "'created' in signoz_storage_result.stdout or 'configured' in signoz_storage_result.stdout"

    - name: Install SigNoz via Helm
      ansible.builtin.command: >
        helm upgrade --install signoz signoz/signoz
        --namespace platform-observability
        --version 0.112.0
        --values {{ manifest_dest }}/kubernetes/platform/signoz/helm.yaml
        --wait
        --timeout 10m
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: signoz_result
      changed_when: "'has been upgraded' in signoz_result.stdout or 'has been installed' in signoz_result.stdout"

    - name: Deploy SigNoz platform resources
      ansible.builtin.command: >
        helm upgrade --install signoz-platform {{ platform_chart }}
        --namespace platform-observability
        --values {{ manifest_dest }}/kubernetes/platform/signoz/platform.yaml
        --wait
        --timeout 2m
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: signoz_platform_result
      changed_when: "'has been upgraded' in signoz_platform_result.stdout or 'has been installed' in signoz_platform_result.stdout"

    # 5. SigNoz K8s infrastructure monitoring
    - name: Install SigNoz K8s infra monitoring via Helm
      ansible.builtin.command: >
        helm upgrade --install signoz-k8s-infra signoz/k8s-infra
        --namespace platform-observability
        --version 0.15.0
        --values {{ manifest_dest }}/kubernetes/platform/signoz-k8s-infra/helm.yaml
        --wait
        --timeout 5m
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: signoz_k8s_result
      changed_when: "'has been upgraded' in signoz_k8s_result.stdout or 'has been installed' in signoz_k8s_result.stdout"

    # 6. n8n workflow automation
    - name: Install n8n via Helm
      ansible.builtin.command: >
        helm upgrade --install n8n community-charts/n8n
        --namespace platform-automation
        --version 1.16.29
        --values {{ manifest_dest }}/kubernetes/platform/n8n/helm.yaml
        --wait
        --timeout 5m
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: n8n_result
      changed_when: "'has been upgraded' in n8n_result.stdout or 'has been installed' in n8n_result.stdout"

    - name: Deploy n8n platform resources
      ansible.builtin.command: >
        helm upgrade --install n8n-platform {{ platform_chart }}
        --namespace platform-automation
        --values {{ manifest_dest }}/kubernetes/platform/n8n/platform.yaml
        --wait
        --timeout 2m
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: n8n_platform_result
      changed_when: "'has been upgraded' in n8n_platform_result.stdout or 'has been installed' in n8n_platform_result.stdout"

    # 7. OpenClaw gateway
    - name: Deploy OpenClaw platform resources
      ansible.builtin.command: >
        helm upgrade --install openclaw-platform {{ platform_chart }}
        --namespace platform-automation
        --values {{ manifest_dest }}/kubernetes/platform/openclaw/platform.yaml
        --wait
        --timeout 2m
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: openclaw_platform_result
      changed_when: "'has been upgraded' in openclaw_platform_result.stdout or 'has been installed' in openclaw_platform_result.stdout"

    - name: Apply OpenClaw deployment
      ansible.builtin.command: kubectl apply -f {{ manifest_dest }}/kubernetes/platform/openclaw/deployment.yaml -n platform-automation
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: openclaw_deploy_result
      changed_when: "'created' in openclaw_deploy_result.stdout or 'configured' in openclaw_deploy_result.stdout"

    # 8. Portainer cluster dashboard
    - name: Install Portainer via Helm
      ansible.builtin.command: >
        helm upgrade --install portainer portainer/portainer
        --namespace platform-management
        --values {{ manifest_dest }}/kubernetes/platform/portainer/helm.yaml
        --wait
        --timeout 5m
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: portainer_result
      changed_when: "'has been upgraded' in portainer_result.stdout or 'has been installed' in portainer_result.stdout"

    - name: Deploy Portainer platform resources
      ansible.builtin.command: >
        helm upgrade --install portainer-platform {{ platform_chart }}
        --namespace platform-management
        --values {{ manifest_dest }}/kubernetes/platform/portainer/platform.yaml
        --wait
        --timeout 2m
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: portainer_platform_result
      changed_when: "'has been upgraded' in portainer_platform_result.stdout or 'has been installed' in portainer_platform_result.stdout"

    - name: Wait for Portainer to be ready
      ansible.builtin.command: kubectl rollout status deployment/portainer -n platform-management --timeout=60s
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      changed_when: false

    - name: Get Portainer service ClusterIP
      ansible.builtin.command: kubectl get svc portainer -n platform-management -o jsonpath='{.spec.clusterIP}'
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: portainer_ip
      changed_when: false

    - name: Initialize Portainer admin user
      ansible.builtin.uri:
        url: "http://{{ portainer_ip.stdout }}:9000/api/users/admin/init"
        method: POST
        body_format: json
        body:
          Username: admin
          Password: "{{ portainer_admin_password }}"
        status_code: [200, 409]
      register: portainer_init
      changed_when: portainer_init.status == 200
      failed_when: false

    # 9. Apply registry manifests
    - name: Apply registry manifests
      ansible.builtin.command: kubectl apply -f {{ manifest_dest }}/kubernetes/platform/registry.yaml
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: registry_result
      changed_when: "'created' in registry_result.stdout or 'configured' in registry_result.stdout"

    - name: Wait for registry to be ready
      ansible.builtin.command: kubectl rollout status deployment/registry -n platform-registry --timeout=60s
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      changed_when: false

    # ========================================
    # Publish app Helm chart to OCI registry
    # ========================================

    - name: Package app Helm chart
      ansible.builtin.command: helm package {{ manifest_dest }}/kubernetes/charts/app --destination /tmp/
      environment:
        KUBECONFIG: "{{ kubeconfig_remote }}"
      register: helm_package_result
      changed_when: true

    - name: Login to OCI registry for Helm
      ansible.builtin.command: >
        helm registry login registry.jterrazz.com
        --username deploy
        --password "{{ registry_password }}"
      no_log: true
      changed_when: false

    - name: Push app chart to OCI registry
      ansible.builtin.command: "helm push {{ helm_package_result.stdout.split(': ')[-1] }} oci://registry.jterrazz.com/charts"
      register: chart_push_result
      changed_when: true

    # ========================================
    # Bootstrap app deployments (opt-in)
    # Triggers each app's CI to deploy via GitHub API.
    # Only needed on fresh cluster rebuild with bootstrap_apps=true.
    # ========================================

    - name: Trigger app CI deployments (jterrazz repos)
      ansible.builtin.uri:
        url: "https://api.github.com/repos/{{ item }}/actions/workflows/deploy.yaml/dispatches"
        method: POST
        headers:
          Authorization: "token {{ github_pat }}"
          Accept: "application/vnd.github.v3+json"
        body_format: json
        body:
          ref: main
        status_code: [204]
      loop:
        - jterrazz/signews-api
        - jterrazz/gateway-intelligence
        - jterrazz/clawssify-web-landing
        - jterrazz/n00-web
      when: github_pat is defined and github_pat | length > 0 and bootstrap_apps | default(false) | bool
      failed_when: false

    - name: Trigger app CI deployments (clawrr repos)
      ansible.builtin.uri:
        url: "https://api.github.com/repos/{{ item }}/actions/workflows/deploy.yaml/dispatches"
        method: POST
        headers:
          Authorization: "token {{ github_pat_clawrr }}"
          Accept: "application/vnd.github.v3+json"
        body_format: json
        body:
          ref: main
        status_code: [204]
      loop:
        - clawrr/web-landing
      when: github_pat_clawrr is defined and github_pat_clawrr | length > 0 and bootstrap_apps | default(false) | bool
      failed_when: false

    # ========================================
    # Cleanup
    # ========================================

    - name: Cleanup temporary manifests
      ansible.builtin.file:
        path: "{{ manifest_dest }}"
        state: absent

    - name: Deployment complete
      ansible.builtin.debug:
        msg: |
          Platform deployment complete!

          Services deployed:
            - cert-manager v1.19.3
            - external-dns v1.20.0
            - infisical v0.10.25
            - signoz v0.112.0 + k8s-infra v0.15.0
            - n8n v1.16.29
            - portainer
            - openclaw
            - registry
          App chart published to: oci://registry.jterrazz.com/charts/app
